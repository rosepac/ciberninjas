---
layout: page
author: rosepac
bootstrap: true
title: ü•á ‚ñ∑ La Gu√≠a Web Completa de Rastreadores Web y robots.txt
description: "Buscadores, rastreadores web, ara√±as, robots y bots; aprende todo para mejorar tu p√°gina web"
excerpt: "Buscadores, rastreadores web, ara√±as, robots y bots; aprende todo para mejorar tu p√°gina web"
published: true
comments: false
date: 2020-03-10
last_modified_at: 
permalink: /robots-txt/
canonical_URL: https://ciberninjas.com/robots-txt/
thumbnail: "/assets/img/robots-txt-lupa-ciberninjas.webp"
feature-img: "/assets/img/robots-txt-lupa-ciberninjas.webp"
img: "/assets/img/robots-txt-lupa-ciberninjas.webp"
# toc: true
# toc_label: "Contenidos"
# toc_icon: user-ninja
# toc_sticky: true
---

Los robots web (tambi√©n conocidos como errantes, rastreadores o ara√±as) son programas que atraviesan la cada p√°gina web de todo el mundo de Internet autom√°ticamente. Los motores de b√∫squeda como Google los usan para indexar el contenido web, los spammers los usan para buscar direcciones de correo electr√≥nico y otros muchos m√°s tienen diferenciados usos.

Con esta p√°gina traemos toda la informaci√≥n necesaria para ser todo un maestro sobre los robots web.

<details>
<summary><strong>MEN√ö üëá</strong><span><a name="menu"></a></span></summary>
<nav class="menu">
  <ol>
    <li><a href="/robots-txt/#qu√©-es-robotstxt">Qu√© es robots.txt</a></li>
    <li><a href="/robots-txt/#al-detalle">Al Detalle</a></li>
    <li><a href="/robots-txt/#c√≥mo-crear-un-archivo-robotstxt">¬øC√≥mo crear un archivo /robots.txt?</a></li>
    <li><a href="/robots-txt/#qu√©-debo-poner-en-este-archivo">¬øQu√© debo poner en este archivo?</a></li>
    <li><a href="/robots-txt/#acerca-de-la-meta-etiqueta-robots">Acerca de la META etiqueta robots</a></li>
    <li><a href="/robots-txt/#c√≥mo-escribir-una-metaetiqueta-de-robots">¬øC√≥mo escribir una metaetiqueta de robots?</a></li>
    <li><a href="/robots-txt/#sitios-de-informaci√≥n-importantes">Sitios de informaci√≥n importantes</a></li>
    <li><a href="/robots-txt/#c√≥mo-chequear-o-probar-tu-robotstxt">C√≥mo chequear o probar tu robots.txt</a></li>
    <li><a href="/robots-txt/#rastreadores-web">Rastreadores web</a></li>
    <li><a href="/robots-txt/#rastreadores-de-c√≥digo-abierto">Rastreadores de c√≥digo abierto</a></li>
  </ol>
</nav>
</details>

> üî• Seguro tambi√©n te interesa: [preguntas frecuentes sobre robots.txt](/robots-txt-preguntas-frecuentes/) >> [recursos webmaster](/recursos-herramientas-webmaster/) >> [aprender posicionamiento web](/posicionamiento-web-seo/) >> [recursos de posicionamiento y seo](/posicionamiento-seo-recursos/) >> [cursos gratis de seo](/cursos-tecnologia/#seo-y-posicionamiento-) >> >> [libros gratis de seo](/biblioteca-de-programacion-y-tecnologia/#seo-y-posicionamiento-) >> [mejores libros de programaci√≥n](/programar/) >> [programas para desarrolladores](/mejores-editores-texto/)
{: .notice--danger}

[üéÅ Ojea las Mejores Ofertas Ninja, ¬°Actualizadas a Diario! üõí](https://www.amazon.es/shop/cibercursos "Los Mejores Chollos de Amazon, Ofertas Flash, Black Monday y Amazon Prime Day"){: .btn .btn-danger .btn-lg .btn-block}{:target="_blank" rel="nofollow,noreferrer"}

## **¬øQu√© es robots.txt?**

Los propietarios de sitios web usan el archivo /robots.txt para dar instrucciones sobre su sitio a los robots web; esto se llama el protocolo de exclusi√≥n de robots.

Funciona as√≠: un robot quiere visitar la URL de un sitio web, por ejemplo, http://www.ejemplo.com/bienvenido.html & antes de hacerlo, primero comprueba si existe el documento: http://www.ejemplo.com/robots.txt y dependiendo del contenido que exista dentro del mismo, actua.

Si el robot encuentra:

{% highlight js %}
User-agent: *
Disallow: /
{% endhighlight %}

La parte de "User-Agent: * "significa que esta secci√≥n se aplica a todos los robots y "Disallow: /" dice al robot que no debe visitar ninguna p√°gina de nuestro sitio web.

Existen dos consideraciones importantes que debes tener en cuenta a la hora de usar /robots.txt:

- Los robots pueden ignorar tu /robots.txt. Especialmente los robots de malware que escanean la web en busca de vulnerabilidades de seguridad y los dedicados a recolectar direcciones de correo electr√≥nico que trabajan como _"spammers"_ no prestar√°n atenci√≥n.
- El archivo /robots.txt es un archivo disponible p√∫blicamente. Osea, cualquiera posee acceso a ver qu√© secciones de su servidor no desea que usen los robots.

Por tanto, no intentes usar /robots.txt para ocultar informaci√≥n.

[‚è´ Regresar al Men√∫](/robots-txt/#menu){: .btn .btn--inverse .btn--large .align-center}

üëâ Ver tambi√©n:<br/>>>[¬øPuedo bloquear solo robots malos?](/robots-txt-preguntas-frecuentes/#se-puede-bloquear-solo-a-los-robots-malos)<br/>>> [¬øPor qu√© este robot ignor√≥ mi /robots.txt?](/robots-txt-preguntas-frecuentes/#por-qu√©-este-robot-ignor√≥-mi-robotstxt)<br/>>> [¬øCu√°les son las implicaciones de seguridad de /robots.txt?](/robots-txt-preguntas-frecuentes/#seguramente-enumerar-archivos-confidenciales-es-un-problema)
{: .notice--danger}

### **Robots.txt al detalle**

Robots.txt es un est√°ndar de facto y no es propiedad de ning√∫n organismo de est√°ndares. Hay dos descripciones hist√≥ricas:

- El documento original de 1994 [A Standard for Robot Exclusion](/standar-original-robots-txt/){:tar}.
<!-- Un borrador de la especificaci√≥n de Internet de 1997 [Un m√©todo para el control de robots web](https://www.robotstxt.org/norobots-rfc.txt) -->
- [Especificaci√≥n HTML 4.01, Ap√©ndice B.4.1](http://www.w3.org/TR/html4/appendix/notes.html#h-B.4.1.1){:target="_blank" rel="nofollow,noreferrer"}
- [Wikipedia - Est√°ndar de exclusi√≥n de robots](http://en.wikipedia.org/wiki/Robots.txt){:target="_blank" rel="nofollow,noreferrer"}

El est√°ndar /robots.txt no se desarrolla activamente. Consulte [¬øQu√© pasa con el desarrollo posterior de /robots.txt? ](https://www.robotstxt.org/faq/future.html)para m√°s discusi√≥n

El resto de esta p√°gina ofrece una descripci√≥n general de c√≥mo usar /robots.txt en su servidor, con algunas recetas simples. Para obtener m√°s informaci√≥n, consulte tambi√©n las [preguntas frecuentes](https://www.robotstxt.org/faq.html) .

[üéÅ Ojea las Mejores Ofertas Ninja, ¬°Actualizadas a Diario! üõí](https://www.amazon.es/shop/cibercursos "Los Mejores Chollos de Amazon, Ofertas Flash, Black Monday y Amazon Prime Day"){: .btn .btn-danger .btn-lg .btn-block}{:target="_blank" rel="nofollow,noreferrer"}

## **¬øC√≥mo crear un archivo /robots.txt?**

**¬øD√≥nde debemos poner el fichero robots.txt?**

La respuesta cortaes, en el directorio de nivel superior de su servidor web.

La respuesta m√°s larga:

Cuando un robot busca el archivo "/robots.txt" para URL, despoja el componente de ruta de la URL (todo desde la primera barra oblicua) y coloca "/robots.txt" en su lugar.

Por ejemplo, para " `https://www.ejemplo.com/shop/index.html` , eliminar√°" `/shop/index.html` ", lo reemplazar√° con" `/robots.txt` "y terminar√° en "https://www.ejemplo.com/robots.txt".

Entonces, como propietario de un sitio web, debe colocarlo en el lugar correcto en su servidor web para que funcione la URL resultante. Por lo general, ese es el mismo lugar donde coloca la p√°gina principal " `index.html` " de bienvenida de tu sitio web . La ruta exacta puede cambiar, dependiendo del software que utilices o de las rutas usadas por tu servidor web.

Recuerde utilizar las letras con min√∫sculas para el nombre de archivo: "robots.txt", y no "Robots.TXT".

[‚è´ Regresar al Men√∫](/robots-txt/#menu){: .btn .btn--inverse .btn--large .align-center}

üëâ Ver tambi√©n:<br/>>> [¬øQu√© programa debo usar para crear /robots.txt?](/robots-txt-preguntas-frecuentes/#qu√©-programa-debo-usar-para-crear-robotstxt)<br/>>> [¬øC√≥mo uso /robots.txt en un host virtual?](/robots-txt-preguntas-frecuentes/#c√≥mo-uso-robotstxt-en-un-host-virtual) <br/>>> [¬øC√≥mo uso /robots.txt en un host compartido?](/robots-txt-preguntas-frecuentes/#c√≥mo-uso-robotstxt-en-un-host-compartido)
{: .notice--danger}

## **¬øQu√© debo poner en este archivo?**

El archivo "/robots.txt" es un archivo de texto, con uno o m√°s registros. Por lo general, contiene un solo registro que se ve as√≠:

{% highlight js %}

User-agent: *
Disallow: /cgi-bin/
Disallow: /tmp/
Disallow: /~carpeta-personal/
{% endhighlight %}

En este ejemplo, se excluyen tres directorios.

Tenga en cuenta que necesita una l√≠nea separada "No permitir" para cada prefijo de URL que desee excluir; no puede decir "No permitir: / cgi-bin / / tmp /" en una sola l√≠nea. Adem√°s, es posible que no tenga l√≠neas en blanco en un registro, ya que se usan para delimitar m√∫ltiples registros.

Tenga en cuenta tambi√©n que el globing y la expresi√≥n regular **no** son compatibles con las l√≠neas User-agent o Disallow. El '*' en el campo Agente de usuario es un valor especial que significa "cualquier robot". Espec√≠ficamente, no puede tener l√≠neas como "User-agent: * bot *", "Disallow: / tmp / *" o "Disallow: * .gif".

Lo que desea excluir depende de su servidor. Todo lo que no se rechaza expl√≠citamente se considera un juego justo para recuperar. Aqu√≠ siguen algunos ejemplos:

### **Para excluir todos los robots de todo el servidor**

{% highlight js %}
User-agent: *
Disallow: /
{% endhighlight %}

### **Para permitir que todos los robots tengan acceso completo**

{% highlight js %}
User-agent: *
Disallow:
{% endhighlight %}

(o simplemente cree un archivo "/robots.txt" vac√≠o, o no use ninguno)

[üéÅ Ojea las Mejores Ofertas Ninja, ¬°Actualizadas a Diario! üõí](https://www.amazon.es/shop/cibercursos "Los Mejores Chollos de Amazon, Ofertas Flash, Black Monday y Amazon Prime Day"){: .btn .btn-danger .btn-lg .btn-block}{:target="_blank" rel="nofollow,noreferrer"}

### **Para excluir todos los robots de parte del servidor**

{% highlight js %}
User-agent: *
Disallow: /cgi-bin/
Disallow: /tmp/
Disallow: /junk/
{% endhighlight %}

### **Para excluir un solo robot**

{% highlight js %}
User-agent: BadBot
Disallow: /
{% endhighlight %}

### **Para permitir un solo robot**

{% highlight js %}
User-agent: Google
Disallow:

User-agent: *
Disallow: /
{% endhighlight %}

### **Para excluir todos los archivos excepto uno**

Esto es actualmente un poco inc√≥modo, ya que no hay un campo "Permitir". La manera f√°cil es colocar todos los archivos que se deshabilitar√°n en un directorio separado, decir "cosas" y dejar el √∫nico archivo en el nivel sobre este directorio:

{% highlight js %}
User-agent: *
Disallow: /~carpeta-personal/stuff/
{% endhighlight %}

Alternativamente, puede rechazar expl√≠citamente todas las p√°ginas no permitidas:

Alternativamente, puede rechazar expl√≠citamente todas las p√°ginas no permitidas:

{% highlight js %}
User-agent: *
Disallow: /~carpeta-personal/junk.html
Disallow: /~carpeta-personal/foo.html
Disallow: /~carpeta-personal/bar.html
{% endhighlight %}

[‚è´ Regresar al Men√∫](/robots-txt/#menu){: .btn .btn--inverse .btn--large .align-center}

[üéÅ Ojea las Mejores Ofertas Ninja, ¬°Actualizadas a Diario! üõí](https://www.amazon.es/shop/cibercursos "Los Mejores Chollos de Amazon, Ofertas Flash, Black Monday y Amazon Prime Day"){: .btn .btn-danger .btn-lg .btn-block}{:target="_blank" rel="nofollow,noreferrer"}

## **Acerca de la META etiqueta robots**

### **En una palabra**

Puede usar una etiqueta HTML especial `META` para indicar a los robots que no indexen el contenido de una p√°gina y / o que no la escaneen para buscar enlaces a seguir.

Por ejemplo:

{% highlight js %}
<html>
<head>
<title> ... </title>
<META NAME="ROBOTS" CONTENT="NOINDEX,NOFOLLOW">
</head>
{% endhighlight %}

Hay dos consideraciones importantes cuando se usa la etiqueta <META> de robots:

- Los robots pueden ignorar su etiqueta <META>. Especialmente los robots de malware que escanean la web en busca de vulnerabilidades de seguridad, y los recolectores de direcciones de correo electr√≥nico utilizados por los spammers no prestar√°n atenci√≥n.
- La directiva NOFOLLOW solo se aplica a los enlaces de esta p√°gina. Es muy probable que un robot encuentre los mismos enlaces en alguna otra p√°gina sin un NOFOLLOW (quiz√°s en alg√∫n otro sitio), y a√∫n as√≠ llegue a su p√°gina no deseada.

No confunda este NOFOLLOW con el atributo de enlace `rel = "nofollow"`](/robots-txt-preguntas-frecuentes/#acerca-de-las-etiquetas-meta).

### **Al detalle**

Al igual que /robots.txt, la etiqueta META de robots es un est√°ndar de facto. Se origin√≥ en una reuni√≥n de un [taller de indexaci√≥n distribuido](http://www.w3.org/Search/9605-Indexing-Workshop/){:target="_blank" rel="nofollow,noreferrer"} en [1996](http://www.w3.org/Search/9605-Indexing-Workshop/){:target="_blank" rel="nofollow,noreferrer"}, y se describi√≥ en las notas de la reuni√≥n.

La etiqueta META tambi√©n se describe en [la especificaci√≥n HTML 4.01, Ap√©ndice B.4.1](http://www.w3.org/TR/html401/appendix/notes.html#h-B.4.1.2){:target="_blank" rel="nofollow,noreferrer"}.

A continuaci√≥n se ofrece una descripci√≥n general de c√≥mo usar las etiquetas <META> de robots en tu p√°gina web, con algunos ejemplos simples. Para obtener m√°s informaci√≥n, consulta nuestra p√°gina de [preguntas frecuentes o FAQ](https://www.robotstxt.org/faq.html).

[üéÅ Ojea las Mejores Ofertas Ninja, ¬°Actualizadas a Diario! üõí](https://www.amazon.es/shop/cibercursos "Los Mejores Chollos de Amazon, Ofertas Flash, Black Monday y Amazon Prime Day"){: .btn .btn-danger .btn-lg .btn-block}{:target="_blank" rel="nofollow,noreferrer"}

## **¬øC√≥mo escribir una metaetiqueta de robots?**

### **¬øD√≥nde situarlo?**

Al igual que cualquier etiqueta <META>, debe colocarse en la secci√≥n HEAD de una p√°gina HTML, como en el ejemplo anterior. Debe ponerlo en cada p√°gina de su sitio, porque un robot puede encontrar un [enlace profundo](http://en.wikipedia.org/wiki/Deep_linking){:target="_blank" rel="nofollow,noreferrer"} a cualquier p√°gina de su sitio.

### **¬øQu√© poner en √©l?**

El atributo "`name`" debe ser "ROBOTS".

Los valores v√°lidos para el atributo "`CONTENT`" son: "`INDEX`", "`NOINDEX`", "`FOLLOW`", "`NOFOLLOW`". Se permiten m√∫ltiples valores separados por comas, pero obviamente solo algunas combinaciones tienen sentido. Si no hay una etiqueta <META> de robots, el valor predeterminado es " `INDEX, NOFOLLOW` ", por lo que no hay necesidad de explicarlo. Eso quedar√≠a:

{% highlight js %}
<META NAME="ROBOTS" CONTENT="NOINDEX, FOLLOW"> 
<META NAME="ROBOTS" CONTENT="INDEX, NOFOLLOW"> 
<META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
{% endhighlight %}

[‚è´ Regresar al Men√∫](/robots-txt/#menu){: .btn .btn--inverse .btn--large .align-center}

## **Sitios de Informaci√≥n Importantes**

- [Mejores Herramientas para Webmasters](https://www.bing.com/toolbox/webmaster)
- [Posicionamiento, Web y SEO](/posicionamiento-web-seo/)

### **El Sitio sobre B√∫squeda y Webmasters de Google**

Muchas personas terminan en este sitio porque tienen preguntas sobre robots y motores de b√∫squeda espec√≠ficos. Para tales preguntas, el mejor lugar son las propias p√°ginas de ayuda del sitio relevante:

- [Centro de ayuda de Google Web Search en Espa√±ol](https://support.google.com/webmasters/search?q=robots){:target="_blank" rel="nofollow,noreferrer"}
- [Centro de ayuda para webmasters de Google](https://www.google.com/intl/es/webmasters/#?modal_active=none){:target="_blank" rel="nofollow,noreferrer"}

[üéÅ Ojea las Mejores Ofertas Ninja, ¬°Actualizadas a Diario! üõí](https://www.amazon.es/shop/cibercursos "Los Mejores Chollos de Amazon, Ofertas Flash, Black Monday y Amazon Prime Day"){: .btn .btn-danger .btn-lg .btn-block}{:target="_blank" rel="nofollow,noreferrer"}

### **Sitios sobre motores de b√∫squeda**

Sitios muy √∫tiles para webmasters:

- [Search Engine Land](http://searchengineland.com/){:target="_blank" rel="nofollow,noreferrer"}
- [Search Engine Watch](http://searchenginewatch.com/){:target="_blank" rel="nofollow,noreferrer"}
- [Mesa redonda de motores de b√∫squeda](http://www.seroundtable.com/){:target="_blank" rel="nofollow,noreferrer"}

<div class="fb-post" data-href="https://www.facebook.com/ciberninjas/posts/1336704793183039" data-width="850" data-show-text="true"><blockquote cite="https://developers.facebook.com/ciberninjas/posts/1336704793183039" class="fb-xfbml-parse-ignore"><p>üîç Los Mejores Libros sobre SEO, Posicionamiento y Marketing Digital; en una sola Colecci√≥n Los Mejores Libros sobre SEO, Posicionamiento y Marketing Digital; en una sola Colecci√≥n üïµÔ∏è‚Äç‚ôÇÔ∏è</p>Publicada por <a href="https://www.facebook.com/ciberninjas/">Ciberninjas</a> en&nbsp;<a href="https://developers.facebook.com/ciberninjas/posts/1336704793183039">Martes, 10 de marzo de 2020</a></blockquote></div>

[‚è´ Regresar al Men√∫](/robots-txt/#menu){: .btn .btn--inverse .btn--large .align-center}

## **¬øC√≥mo chequear o probar tu robots.txt?**

- [Herramienta de prueba del fichero robots de Chrome](https://support.google.com/webmasters/answer/6062598?hl=es)

## **Rastreadores web**
<!-- https://www.keycdn.com/blog/web-crawlers -->
- [Bingbot](https://en.wikipedia.org/wiki/Bingbot){:target="_blank" rel="nofollow,noreferrer"} es el nombre del [webcrawler](https://en.wikipedia.org/wiki/Bingbot){:target="_blank" rel="nofollow,noreferrer"} de [Bing](https://en.wikipedia.org/wiki/Bing_(search_engine)){:target="_blank" rel="nofollow,noreferrer"} de Microsoft . Reemplaz√≥ a *[Msnbot](https://en.wikipedia.org/wiki/Msnbot){:target="_blank" rel="nofollow,noreferrer"}* .
- [Googlebot](https://en.wikipedia.org/wiki/Googlebot){:target="_blank" rel="nofollow,noreferrer"} se describe con cierto detalle, pero la referencia es solo sobre una versi√≥n temprana de su arquitectura, que estaba basada en C ++ y [Python](https://en.wikipedia.org/wiki/Python_(programming_language)){:target="_blank" rel="nofollow,noreferrer"} . El rastreador se integr√≥ con el proceso de indexaci√≥n, porque el an√°lisis de texto se realiz√≥ para la indexaci√≥n de texto completo y tambi√©n para la extracci√≥n de URL. Hay un servidor de URL que env√≠a listas de URL para que sean recuperadas por varios procesos de rastreo. Durante el an√°lisis, las URL encontradas se pasaron a un servidor de URL que verific√≥ si la URL se hab√≠a visto anteriormente. De lo contrario, la URL se agreg√≥ a la cola del servidor de URL.
- [SortSite](https://en.wikipedia.org/wiki/SortSite){:target="_blank" rel="nofollow,noreferrer"}
- Swiftbot es el rastreador web de [Swiftype](https://en.wikipedia.org/wiki/Swiftype){:target="_blank" rel="nofollow,noreferrer"} .
- [WebCrawler](https://en.wikipedia.org/wiki/WebCrawler){:target="_blank" rel="nofollow,noreferrer"} se utiliz√≥ para crear el primer √≠ndice de texto completo disponible p√∫blicamente de un subconjunto de la Web. Se bas√≥ en lib-WWW para descargar p√°ginas, y otro programa para analizar y ordenar URL para una exploraci√≥n m√°s amplia del gr√°fico web. Tambi√©n inclu√≠a un rastreador en tiempo real que segu√≠a enlaces basados en la similitud del texto de anclaje con la consulta proporcionada.
- [WebFountain](https://en.wikipedia.org/wiki/WebFountain){:target="_blank" rel="nofollow,noreferrer"} es un rastreador modular distribuido similar a Mercator pero escrito en C ++.
- [World Wide Web Worm](https://en.wikipedia.org/wiki/World_Wide_Web_Worm){:target="_blank" rel="nofollow,noreferrer"} fue un rastreador utilizado para crear un √≠ndice simple de t√≠tulos de documentos y URL. Se puede buscar el √≠ndice utilizando el `comando grep` [Unix](https://en.wikipedia.org/wiki/Unix){:target="_blank" rel="nofollow,noreferrer"} .
- [Xenon](https://en.wikipedia.org/wiki/Xenon_(program)) es un rastreador web utilizado por las autoridades fiscales del gobierno para detectar fraudes.
- Yahoo! Slurp era el nombre de [Yahoo! ](https://en.wikipedia.org/wiki/Yahoo!){:target="_blank" rel="nofollow,noreferrer"} buscador, el rastreador de Yahoo! contratado con [Microsoft](https://en.wikipedia.org/wiki/Microsoft){:target="_blank" rel="nofollow,noreferrer"} para usar [Bingbot](https://en.wikipedia.org/wiki/Bingbot){:target="_blank" rel="nofollow,noreferrer"} en [su](https://en.wikipedia.org/wiki/Bingbot){:target="_blank" rel="nofollow,noreferrer"} lugar.

[‚è´ Regresar al Men√∫](/robots-txt/#menu){: .btn .btn--inverse .btn--large .align-center}

[üéÅ Ojea las Mejores Ofertas Ninja, ¬°Actualizadas a Diario! üõí](https://www.amazon.es/shop/cibercursos "Los Mejores Chollos de Amazon, Ofertas Flash, Black Monday y Amazon Prime Day"){: .btn .btn-danger .btn-lg .btn-block}{:target="_blank" rel="nofollow,noreferrer"}

## **Rastreadores de c√≥digo abierto**

- [Frontera](https://en.wikipedia.org/wiki/Frontera_(web_crawling)){:target="_blank" rel="nofollow,noreferrer"} es un framework de rastreo web que implementa el componente de [frontera de rastreo](https://en.wikipedia.org/wiki/Crawl_frontier){:target="_blank" rel="nofollow,noreferrer"} y proporciona primitivas de escalabilidad para aplicaciones de [rastreo](https://en.wikipedia.org/wiki/Crawl_frontier){:target="_blank" rel="nofollow,noreferrer"} web.
- [GNU Wget](https://en.wikipedia.org/wiki/Wget){:target="_blank" rel="nofollow,noreferrer"} es un rastreador operado por [l√≠nea de](https://en.wikipedia.org/wiki/Command_line_interface){:target="_blank" rel="nofollow,noreferrer"} comandos escrito en [C](https://en.wikipedia.org/wiki/C_(programming_language)){:target="_blank" rel="nofollow,noreferrer"} y lanzado bajo la [GPL](https://en.wikipedia.org/wiki/GNU_General_Public_License){:target="_blank" rel="nofollow,noreferrer"}. Por lo general, se usa para reflejar sitios web y FTP.
- [GRUB](https://en.wikipedia.org/wiki/Grub_(search_engine)){:target="_blank" rel="nofollow,noreferrer"} es un rastreador de b√∫squeda distribuida de c√≥digo abierto que [Wikia Search](https://en.wikipedia.org/wiki/Wikia_Search){:target="_blank" rel="nofollow,noreferrer"} us√≥ para rastrear la web.
- [Heritrix](https://en.wikipedia.org/wiki/Heritrix){:target="_blank" rel="nofollow,noreferrer"} es el rastreador de calidad de archivo de [Internet Archive](https://en.wikipedia.org/wiki/Internet_Archive){:target="_blank" rel="nofollow,noreferrer"}, dise√±ado para archivar instant√°neas peri√≥dicas de una gran parte de la Web. Fue escrito en [Java](https://en.wikipedia.org/wiki/Java_(programming_language)){:target="_blank" rel="nofollow,noreferrer"}.
- [ht: // Dig](https://en.wikipedia.org/wiki/Ht-//dig){:target="_blank" rel="nofollow,noreferrer"} incluye un rastreador web en su motor de indexaci√≥n.
- [HTTrack](https://en.wikipedia.org/wiki/HTTrack){:target="_blank" rel="nofollow,noreferrer"} utiliza un rastreador web para crear un espejo de un sitio web para su visualizaci√≥n fuera de l√≠nea. Est√° escrito en [C](https://en.wikipedia.org/wiki/C_(programming_language)){:target="_blank" rel="nofollow,noreferrer"} y publicado bajo la [GPL](https://en.wikipedia.org/wiki/GNU_General_Public_License){:target="_blank" rel="nofollow,noreferrer"}.
- [mnoGoSearch](https://en.wikipedia.org/wiki/MnoGoSearch){:target="_blank" rel="nofollow,noreferrer"} es un rastreador, indexador y un motor de b√∫squeda escrito en C y con licencia bajo la [GPL](https://en.wikipedia.org/wiki/GNU_General_Public_License){:target="_blank" rel="nofollow,noreferrer"} (* solo m√°quinas NIX)
- [Norconex HTTP Collector](https://en.wikipedia.org/wiki/Norconex_HTTP_Collector){:target="_blank" rel="nofollow,noreferrer"} es una ara√±a web, o rastreador, escrita en [Java](https://en.wikipedia.org/wiki/Java_(programming_language)){:target="_blank" rel="nofollow,noreferrer"} , que tiene como objetivo facilitar la vida de los integradores y desarrolladores de Enterprise Search (con licencia de [Apache License](https://en.wikipedia.org/wiki/Apache_License){:target="_blank" rel="nofollow,noreferrer"}.
- [Apache Nutch](https://en.wikipedia.org/wiki/Apache_Nutch){:target="_blank" rel="nofollow,noreferrer"} es un rastreador web altamente extensible y escalable escrito en Java y lanzado bajo una [licencia de Apache](https://en.wikipedia.org/wiki/Apache_License){:target="_blank" rel="nofollow,noreferrer"}. Est√° basado en [Apache Hadoop](https://en.wikipedia.org/wiki/Apache_Hadoop){:target="_blank" rel="nofollow,noreferrer"} y puede usarse con [Apache Solr](https://en.wikipedia.org/wiki/Apache_Solr){:target="_blank" rel="nofollow,noreferrer"} o [Elasticsearch](https://en.wikipedia.org/wiki/Elasticsearch){:target="_blank" rel="nofollow,noreferrer"}.
- [Open Search Server](https://en.wikipedia.org/wiki/Open_Search_Server){:target="_blank" rel="nofollow,noreferrer"} es un motor de b√∫squeda y una versi√≥n de software de rastreador web bajo la [GPL](https://en.wikipedia.org/wiki/GNU_General_Public_License){:target="_blank" rel="nofollow,noreferrer"}.
- [PHP-Crawler](https://en.wikipedia.org/wiki/PHP-Crawler){:target="_blank" rel="nofollow,noreferrer"} es un simple rastreador basado en [PHP](https://en.wikipedia.org/wiki/PHP){:target="_blank" rel="nofollow,noreferrer"} y [MySQL](https://en.wikipedia.org/wiki/MySQL){:target="_blank" rel="nofollow,noreferrer"} lanzado bajo la [Licencia BSD](https://en.wikipedia.org/wiki/BSD_License){:target="_blank" rel="nofollow,noreferrer"}.
- [Scrapy](https://en.wikipedia.org/wiki/Scrapy){:target="_blank" rel="nofollow,noreferrer"}, un framework de [webcrawler de](https://en.wikipedia.org/wiki/Scrapy){:target="_blank" rel="nofollow,noreferrer"} c√≥digo abierto, escrito en python (licenciado bajo [BSD](https://en.wikipedia.org/wiki/BSD_License){:target="_blank" rel="nofollow,noreferrer"}.
- [Seeks](https://en.wikipedia.org/wiki/Seeks){:target="_blank" rel="nofollow,noreferrer"}, un motor de b√∫squeda distribuido gratuito (con licencia [AGPL](https://en.wikipedia.org/wiki/GNU_Affero_General_Public_License){:target="_blank" rel="nofollow,noreferrer"}.
- [StormCrawler](https://en.wikipedia.org/wiki/StormCrawler){:target="_blank" rel="nofollow,noreferrer"}, una colecci√≥n de recursos para crear rastreadores web escalables y de baja latencia en [Apache Storm](https://en.wikipedia.org/wiki/Storm_(event_processor)){:target="_blank" rel="nofollow,noreferrer"} ( [licencia de Apache](https://en.wikipedia.org/wiki/Apache_License){:target="_blank" rel="nofollow,noreferrer"} ).
- [tkWWW Robot](https://en.wikipedia.org/wiki/TkWWW_Robot){:target="_blank" rel="nofollow,noreferrer"}, un rastreador basado en el navegador web [tkWWW](https://en.wikipedia.org/wiki/TkWWW){:target="_blank" rel="nofollow,noreferrer"} (con licencia bajo [GPL](https://en.wikipedia.org/wiki/GNU_General_Public_License){:target="_blank" rel="nofollow,noreferrer"} ).
- [Xapian](https://en.wikipedia.org/wiki/Xapian){:target="_blank" rel="nofollow,noreferrer"}, un motor de b√∫squeda de rastreadores, escrito en c ++.
- [YaCy](https://en.wikipedia.org/wiki/YaCy){:target="_blank" rel="nofollow,noreferrer"}, un motor de b√∫squeda distribuido gratuito, basado en los principios de las redes punto a punto (con licencia bajo [GPL](https://en.wikipedia.org/wiki/GNU_General_Public_License){:target="_blank" rel="nofollow,noreferrer"} ).
- [Trandoshan](https://github.com/trandoshan-io){:target="_blank" rel="nofollow,noreferrer"}, un rastreador web distribuido de c√≥digo abierto y gratuito dise√±ado para la web profunda.

[‚è´ Regresar al Men√∫](/robots-txt/#menu){: .btn .btn--inverse .btn--large .align-center}

[üéÅ Ojea las Mejores Ofertas Ninja, ¬°Actualizadas a Diario! üõí](https://www.amazon.es/shop/cibercursos "Los Mejores Chollos de Amazon, Ofertas Flash, Black Monday y Amazon Prime Day"){: .btn .btn-danger .btn-lg .btn-block}{:target="_blank" rel="nofollow,noreferrer"}
<!-- https://www.keycdn.com/blog/web-crawlers los 10 rastreadores web m√°s conocidos. -->
<!-- https://prowebscraper.com/blog/50-best-open-source-web-crawlers/ Los 50 Rastreadores Web M√°s -->
<!-- https://www.nichemarket.co.za/blog/nichemarket-advice/6-web-crawling-tools 6 herramientas de web rastreo -->

<!-- - [Automatic indexing](https://en.wikipedia.org/wiki/Automatic_indexing)
- [Gnutella crawler](https://en.wikipedia.org/wiki/Gnutella_crawler)
- [Web archiving](https://en.wikipedia.org/wiki/Web_archiving)
- [Webgraph](https://en.wikipedia.org/wiki/Webgraph)
- [Website mirroring software](https://en.wikipedia.org/wiki/Website_mirroring_software)
- [Search Engine Scraping](https://en.wikipedia.org/wiki/Search_Engine_Scraping) -->