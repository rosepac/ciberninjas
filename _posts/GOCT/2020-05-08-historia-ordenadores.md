---

author_profile: true
comments: false
classes: wide
tags:
- Historia Ordenadores
categories:
- GOCT
header:
  teaser: /assets/images/blog/
title: 'Breve historia de los ordenadores'
description: >-
  Una historia de computadoras f√°cil de entender, desde el √°baco hasta Internet y iPhone.
excerpt: >-
  Una historia de computadoras f√°cil de entender, desde el √°baco hasta Internet y iPhone.
canonical_URL: https://ciberninjas.com/historia-ordenadores/
permalink: /historia-ordenadores/
date: 2020-05-08 00:32:32
last_modified_at: 
published: false

---

![](/assets/images/ "")

- [1. **√Åbacos y calculadoras**](#1-%c3%81bacos-y-calculadoras)
- [2. **Motores de c√°lculo**](#2-motores-de-c%c3%a1lculo)
- [3. **Bush y la bomba**](#3-bush-y-la-bomba)
- [4. **Turing: Probando**](#4-turing-probando)
- [5. **Las primeras computadoras modernas**](#5-las-primeras-computadoras-modernas)
- [6. **La revoluci√≥n micro electr√≥nica**](#6-la-revoluci%c3%b3n-micro-electr%c3%b3nica)
- [7. **Computadoras personales**](#7-computadoras-personales)
- [8. **La revoluci√≥n del usuario**](#8-la-revoluci%c3%b3n-del-usuario)
- [9. **De las redes a internet**](#9-de-las-redes-a-internet)
- [10. **¬øQu√© nos espera en el futuro?**](#10-%c2%bfqu%c3%a9-nos-espera-en-el-futuro)
  - [Relacionados](#relacionados)

üî• Seguro tambi√©n te interesa: [mejores libros de programaci√≥n](/programar/) >> [programas para desarrolladores](/mejores-sistemas-operativos-para-hackear/) >> [mejores lenguajes de programaci√≥n](/15-mejores-lenguajes-programacion/) >> [port√°tiles para programadores]() >> [mejores auriculares para programadores](/auriculares-dise%C3%B1o/) >> [ratones verticales para trabajar](/teclados-ratones-dise%C3%B1o/) >> [componentes de PC para programadores](/ordenadores-componentes/) >> [mejores regalos 1 - üì¶](/black-friday-amazon/) >> [mejores regalos 2 - üéÅ](/prime-day-amazon/)
{: .notice--danger}

Las computadoras realmente se convirtieron en grandes inventos en las √∫ltimas dos d√©cadas del siglo XX. Pero su historia se remonta m√°s de 2500 a√±os atr√°s al √°baco: una calculadora simple hecha de cuentas y alambres, que todav√≠a se usa en algunas partes del mundo en la actualidad. La diferencia entre un √°baco antiguo y una computadora moderna parece enorme, pero el principio, hacer c√°lculos repetidos m√°s r√°pidamente que el cerebro humano, es exactamente el mismo.

<!-- https://www.explainthatstuff.com/historyofcomputers.html -->

## 1. **√Åbacos y calculadoras**

Es una medida del brillo del √°baco, inventado en el Medio Oriente alrededor del a√±o 500 a. C., que sigui√≥ siendo la forma m√°s r√°pida de calculadora hasta mediados del siglo XVII.

Luego, en 1642, con solo 18 a√±os, el cient√≠fico y fil√≥sofo franc√©s Blaise Pascal (1623-1666) invent√≥ la primera calculadora mec√°nica pr√°ctica , la Pascalina, para ayudar a su padre recaudador de impuestos a hacer sumas. La m√°quina ten√≠a una serie de dientes entrelazados (ruedas dentadas con dientes alrededor de sus bordes exteriores) que pod√≠an sumar y restar n√∫meros decimales.

Varias d√©cadas despu√©s, en 1671, el matem√°tico y fil√≥sofo alem√°n Gottfried Wilhelm Leibniz(1646-1716) se le ocurri√≥ una m√°quina similar pero m√°s avanzada.

En lugar de usar engranajes, ten√≠a un "tambor escalonado" (un cilindro con dientes de longitud creciente alrededor de su borde), una innovaci√≥n que sobrevivi√≥ en las calculadoras mec√°nicas durante 300 a√±os. La m√°quina Leibniz podr√≠a hacer mucho m√°s que la de Pascal: adem√°s de sumar y restar, podr√≠a multiplicar, dividir y resolver ra√≠ces cuadradas. Otra caracter√≠stica pionera fue el primer almac√©n de memoria o "registro".

Adem√°s de desarrollar una de las primeras calculadoras mec√°nicas del mundo, Leibniz es recordado por otra contribuci√≥n importante a la inform√°tica: fue el hombre que invent√≥ el c√≥digo binario, una forma de representar cualquier n√∫mero decimal usando solo los dos d√≠gitos cero y uno. Aunque Leibniz no hizo uso del binario en su propia calculadora, hizo pensar a otros.

En 1854, poco m√°s de un siglo despu√©s de la muerte de Leibniz, el ingl√©s George Boole (1815-1864) utiliz√≥ la idea para inventar una nueva rama de las matem√°ticas llamada √°lgebra booleana.

En las computadoras modernas, el c√≥digo binario y el √°lgebra booleana permiten que las computadoras tomen decisiones simples al comparar largas cadenas de ceros y unos. Pero, en el siglo XIX, estas ideas todav√≠a estaban muy adelantadas a su tiempo. A los matem√°ticos e inform√°ticos les llevar√≠a otros 50 a 100 a√±os descubrir c√≥mo usarlos (descubra m√°s en nuestros art√≠culos sobre calculadoras y puertas l√≥gicas ).

## 2. **Motores de c√°lculo**

Ni el √°baco ni las calculadoras mec√°nicas construidas por Pascal y Leibniz realmente fueron calificadas como computadoras. Una calculadora es un dispositivo que facilita y agiliza el c√°lculo de las personas, pero necesita un operador humano.

Una computadora, por otro lado, es una m√°quina que puede operar autom√°ticamente, sin ayuda humana, siguiendo una serie de instrucciones almacenadas llamadas programa (una especie de receta matem√°tica). Las calculadoras se convirtieron en computadoras cuando las personas idearon formas de hacer calculadoras programables y totalmente autom√°ticas.

C√≥mo se usaban las tarjetas perforadas en las primeras computadoras.  Un dibujo de la Patente Art of Compiling Statistics de Herman Hollerith, 8 de enero de 1889.

Foto: Tarjetas perforadas: Herman Hollerith perfeccion√≥ la forma de usar tarjetas perforadas y cinta de papel para almacenar informaci√≥n y alimentarla en una m√°quina. Existen dibujos de su Arte de compilaci√≥n de estad√≠sticas de 1889 (Patente de EE. UU. # 395,782), que muestra c√≥mo se perfora una tira de papel (amarillo) con diferentes patrones de agujeros (naranja) que corresponden a las estad√≠sticas recopiladas sobre las personas en el censo de EE. UU. Imagen cortes√≠a de la Oficina de Patentes y Marcas de los Estados Unidos.

La primera persona en intentar esto fue un matem√°tico ingl√©s bastante obsesivo y notoriamente gru√±√≥n llamado Charles Babbage (1791-1871). Muchos consideran a Babbage como el "padre de la computadora" porque sus m√°quinas ten√≠an una entrada (una forma de alimentar los n√∫meros), una memoria (algo para almacenar estos n√∫meros mientras se realizaban c√°lculos complejos), un procesador (el generador de n√∫meros que llev√≥ a cabo los c√°lculos) y una salida (un mecanismo de impresi√≥n), los mismos componentes b√°sicos compartidos por todas las computadoras modernas.

Durante su vida, Babbage nunca complet√≥ una sola de las m√°quinas enormemente ambiciosas que intent√≥ construir. Eso no fue una sorpresa. Cada uno de sus "motores" programables fue dise√±ado para usar decenas de miles de engranajes hechos con precisi√≥n., una m√°quina Pascal o Leibniz aumentaba mil veces en dimensiones, ambici√≥n y complejidad.

Durante un tiempo, el gobierno brit√°nico financi√≥ Babbage, por un monto de ¬£ 17,000, luego una suma enorme. Pero cuando Babbage presion√≥ al gobierno para obtener m√°s dinero para construir una m√°quina a√∫n m√°s avanzada, perdieron la paciencia y se retiraron. Babbage fue m√°s afortunado al recibir ayuda de Augusta Ada Byron (1815-1852), condesa de Lovelace, hija del poeta Lord Byron.

Como matem√°tica entusiasta, ayud√≥ a refinar las ideas de Babbage para hacer que su m√°quina fuera programable, y es por eso que a veces se la conoce como la primera programadora de computadoras del mundo. Poco del trabajo de Babbage sobrevivi√≥ despu√©s de su muerte. Pero cuando, por casualidad, sus cuadernos fueron redescubiertos en la d√©cada de 1930, los inform√°ticos finalmente apreciaron el brillo de sus ideas. Desafortunadamente, para entonces, la mayor√≠a de estas ideas ya hab√≠an sido reinventadas por otros.

Babbage ten√≠a la intenci√≥n de que su m√°quina eliminara el trabajo pesado de los c√°lculos repetitivos. Originalmente, se imagin√≥ que ser√≠a usado por el ej√©rcito para compilar las tablas que ayudaron a sus artilleros a disparar ca√±ones con mayor precisi√≥n.

Hacia finales del siglo XIX, otros inventores tuvieron m√°s √©xito en su esfuerzo por construir "motores" de c√°lculo. Estad√≠stico estadounidense Herman Hollerith(1860‚Äì1929) construyeron una de las primeras m√°quinas de c√°lculo pr√°cticas del mundo, a la que llam√≥ tabulador, para ayudar a compilar datos del censo.

Entonces, como ahora, se realizaba un censo cada d√©cada, pero, en la d√©cada de 1880, la poblaci√≥n de los Estados Unidos hab√≠a crecido tanto a trav√©s de la inmigraci√≥n que un an√°lisis a gran escala de los datos a mano llevaba siete a√±os y medio. Los estad√≠sticos pronto descubrieron que, si las tendencias continuaban, se les agotar√≠a el tiempo para compilar un censo antes de que venza el siguiente.

Afortunadamente, el tabulador de Hollerith fue un √©xito incre√≠ble: cont√≥ todo el censo en solo seis semanas y complet√≥ el an√°lisis completo en solo dos a√±os y medio. Poco despu√©s, Hollerith se dio cuenta de que su m√°quina ten√≠a otras aplicaciones, por lo que cre√≥ la Tabulation Machine Company en 1896 para fabricarla comercialmente.

## 3. **Bush y la bomba**

La historia de la computaci√≥n recuerda personajes coloridos como Babbage, pero otros que desempe√±aron roles importantes, aunque de apoyo, son menos conocidos. En el momento en que CTR se estaba convirtiendo en IBM, el cient√≠fico del gobierno estadounidense Vannevar Bush (1890-1974) estaba desarrollando las calculadoras m√°s potentes del mundo.

En 1925, Bush hizo el primero de una serie de artilugios dif√≠ciles de manejar con nombres igualmente engorrosos: el nuevo multiplicador de interacciones de productos de grabaci√≥n. M√°s tarde, construy√≥ una m√°quina llamada Analizador diferencial, que utilizaba engranajes, correas, palancas y ejes para representar n√∫meros y realizar c√°lculos de una manera muy f√≠sica, como una gigantesca regla de c√°lculo mec√°nico.

La calculadora definitiva de Bush fue una m√°quina mejorada llamada Analizador diferencial Rockefeller, ensamblada en 1935 a partir de 320 km (200 millas) de cable y 150motores electricos . Las m√°quinas como estas se conoc√≠an como calculadoras anal√≥gicas , anal√≥gicas porque almacenaban n√∫meros en forma f√≠sica (como tantas vueltas en una rueda o giros de una correa) en lugar de d√≠gitos. Aunque pudieron realizar c√°lculos incre√≠blemente complejos, se necesitaron varios d√≠as para hacer girar las ruedas y girar la correa antes de que finalmente aparecieran los resultados.

Impresionantes m√°quinas como el Analizador Diferencial fueron solo una de varias contribuciones sobresalientes que Bush hizo a la tecnolog√≠a del siglo XX. Otro vino como el maestro de Claude Shannon (1916‚Äì2001), un matem√°tico brillante que descubri√≥ c√≥mo los circuitos el√©ctricos pod√≠an vincularse para procesar c√≥digo binario con √°lgebra booleana (una forma de comparar n√∫meros binarios usando la l√≥gica) y as√≠ tomar decisiones simples.

Durante la Segunda Guerra Mundial, el presidente Franklin D. Roosevelt nombr√≥ al presidente de Bush primero del Comit√© de Investigaci√≥n de Defensa Nacional de los Estados Unidos y luego director de la Oficina de Investigaci√≥n y Desarrollo Cient√≠fico (OSRD).

En esta capacidad, estuvo a cargo del Proyecto Manhattan, la iniciativa secreta de 2 mil millones de d√≥lares que condujo a la creaci√≥n de la bomba at√≥mica. Una de las contribuciones finales de Bush en tiempo de guerra fue esbozar, en 1945, una idea para un dispositivo de almacenamiento y uso compartido de memoria llamado Memex que luego inspirar√≠a a Tim Berners-Lee a inventar la World Wide Web.

Pocos fuera del mundo de la inform√°tica recuerdan a Vannevar Bush hoy, ¬°pero qu√© legado! Como padre de la computadora digital, un supervisor de la bomba at√≥mica y una inspiraci√≥n para la Web, Bush jug√≥ un papel fundamental en tres de las tecnolog√≠as de mayor alcance del siglo XX.

## 4. **Turing: Probando**

Muchos de los pioneros de la inform√°tica fueron experimentadores pr√°cticos, pero de ninguna manera todos ellos. Una de las figuras clave en la historia de la inform√°tica del siglo XX, Alan Turing (1912‚Äì1954) fue un brillante matem√°tico de Cambridge cuyas principales contribuciones fueron a la teor√≠a.de c√≥mo las computadoras procesaron la informaci√≥n.

En 1936, a la edad de solo 23 a√±os, Turing escribi√≥ un art√≠culo matem√°tico innovador llamado "Sobre n√∫meros computables, con una aplicaci√≥n al problema Entscheidungs", en el que describi√≥ una computadora te√≥rica ahora conocida como m√°quina de Turing (un procesador de informaci√≥n simple que funciona a trav√©s de una serie de instrucciones, leer datos, escribir resultados y luego pasar a la siguiente instrucci√≥n). Las ideas de Turing fueron muy influyentes en los a√±os siguientes y muchas personas lo consideran el padre de la inform√°tica moderna, el equivalente de Babbage del siglo XX.

Aunque esencialmente era un te√≥rico, Turing se involucr√≥ con maquinaria real y pr√°ctica, a diferencia de muchos matem√°ticos de su tiempo. Durante la Segunda Guerra Mundial, desempe√±√≥ un papel fundamental en el desarrollo de maquinaria para descifrar c√≥digos que, en s√≠ misma, desempe√±√≥ un papel clave en la victoria brit√°nica en tiempos de guerra.

M√°s tarde, jug√≥ un papel menor en la creaci√≥n de varias computadoras experimentales a gran escala, incluyendo ACE (Automatic Computing Engine), Colossus y el Manchester / Ferranti Mark I (descrito a continuaci√≥n).

Hoy, Alan Turing es m√°s conocido por concebir lo que se conoce como la prueba de Turing, una forma simple de averiguar si una computadora puede considerarse inteligente al comprobar si puede o no mantener una conversaci√≥n plausible con un ser humano real.

## 5. **Las primeras computadoras modernas**

Los a√±os de la Segunda Guerra Mundial fueron un per√≠odo crucial en la historia de la inform√°tica, cuando comenzaron a aparecer poderosas computadoras gigantes. Justo antes del estallido de la guerra, en 1938, el ingeniero alem√°n Konrad Zuse (1910‚Äì1995) construy√≥ su Z1, la primera computadora binaria programable del mundo, en la sala de estar de sus padres.

Al a√±o siguiente, el f√≠sico estadounidense John Atanasoff (1903‚Äì1995) y su asistente, el ingeniero el√©ctrico Clifford Berry(1918‚Äì1963), construyeron una m√°quina binaria m√°s elaborada que llamaron Atanasoff Berry Computer (ABC).

Fue un gran avance, 1000 veces m√°s preciso que el analizador diferencial de Bush. Estas fueron las primeras m√°quinas que utilizaron interruptores el√©ctricos para almacenar n√∫meros: cuando un interruptor estaba "apagado", almacenaba el n√∫mero cero; volteado a su otra posici√≥n, "encendido", almacen√≥ el n√∫mero uno.

Cientos o miles de conmutadores podr√≠an almacenar una gran cantidad de d√≠gitos binarios (aunque el binario es mucho menos eficiente a este respecto que el decimal, ya que se necesitan hasta ocho d√≠gitos binarios para almacenar un n√∫mero decimal de tres d√≠gitos). Estas m√°quinas eran computadoras digitales: a diferencia de las m√°quinas anal√≥gicas, que almacenaban n√∫meros usando las posiciones de ruedas y barras, almacenaban n√∫meros como d√≠gitos.

La primera computadora digital a gran escala de este tipo apareci√≥ en 1944 en la Universidad de Harvard, construida por el matem√°tico Howard Aiken (1900-1973). Patrocinado por IBM, se le conoc√≠a como Harvard Mark I o Calculadora autom√°tica de secuencia controlada de IBM (ASCC).

Una m√°quina gigante, con una longitud de 15 m (50 pies), era como una enorme calculadora mec√°nica integrada en una pared. Debe haber sonado impresionante, porque almacenaba y procesaba n√∫meros usando rel√©s electromagn√©ticos "clickety-clack" (imanes operados el√©ctricamente que cambiaban autom√°ticamente las l√≠neas en el tel√©fonointercambios): no menos de 3304 de ellos.

Puede que hayan sido impresionantes, pero los relevos sufrieron varios problemas: eran grandes (por eso el Harvard Mark I ten√≠a que ser tan grande); necesitaban fuertes impulsos de poder para hacerlos cambiar; y eran lentos (tom√≥ un tiempo para que un rel√© cambiara de "apagado" a "encendido" o de 0 a 1).

La mayor√≠a de las m√°quinas desarrolladas en esta √©poca estaban destinadas a fines militares. Al igual que los motores mec√°nicos nunca construidos de Babbage, fueron dise√±ados para calcular las mesas de tiro de artiller√≠a y analizar las otras tareas complejas que entonces eran la gran cantidad de matem√°ticos militares.

Durante la Segunda Guerra Mundial, los militares cooptaron a miles de las mejores mentes cient√≠ficas: reconociendo que la ciencia ganar√≠a la guerra, la Oficina de Investigaci√≥n y Desarrollo Cient√≠fico de Vannevar Bush emple√≥ a 10,000 cient√≠ficos solo de los Estados Unidos. Las cosas eran muy diferentes en Alemania. Cuando Konrad Zuse ofreci√≥ construir su computadora Z2 para ayudar al ej√©rcito, no pudieron ver la necesidad y lo rechazaron.

Del lado aliado, las grandes mentes comenzaron a hacer grandes avances. En 1943, un equipo de matem√°ticos con sede en Bletchley Park, cerca de Londres, Inglaterra (incluido Alan Turing) construy√≥ una computadora llamada Coloso para ayudarlos a descifrar c√≥digos secretos alemanes. Coloso fue la primera computadora totalmente electr√≥nica.

En lugar de rel√©s, utiliz√≥ una mejor forma de interruptor conocido como tubo de vac√≠o (tambi√©n conocido, especialmente en Gran Breta√±a, como v√°lvula). El tubo de vac√≠o, cada uno tan grande como el pulgar de una persona y brillando al rojo vivo como una peque√±a bombilla el√©ctrica, fue inventado en 1906 por Lee de Forest (1873-1961), quien lo llam√≥ Audion.

Este avance le vali√≥ a De Forest su sobrenombre como "el padre de la radio" porque su primer uso importante fue en receptores de radio , donde amplificaron se√±ales entrantes d√©biles para que las personas puedan escucharlas con mayor claridad.

En computadoras como ABC y Colossus, los tubos de vac√≠o encontraron un uso alternativo como interruptores m√°s r√°pidos y compactos.

Al igual que los c√≥digos que intentaba descifrar, Coloso era de alto secreto y su existencia no se confirm√≥ hasta despu√©s de que termin√≥ la guerra. En lo que respecta a la mayor√≠a de las personas, los tubos de vac√≠o fueron pioneros de una computadora m√°s visible que apareci√≥ en 1946: el Calculador e Integrador Num√©rico Electr√≥nico (ENIAC).

Los inventores de ENIAC, dos cient√≠ficos de la Universidad de Pennsylvania, John Mauchly (1907‚Äì1980) y J. Presper Eckert (1919‚Äì1995), se inspiraron originalmente en el analizador diferencial de Bush; a√±os m√°s tarde, Eckert record√≥ que ENIAC era el "descendiente de la m√°quina del Dr. Bush".

Pero la m√°quina que construyeron era mucho m√°s ambiciosa. Conten√≠a cerca de 18,000 tubos de vac√≠o (nueve veces m√°s que Coloso), med√≠a alrededor de 24 m (80 pies) de largo y pesaba casi 30 toneladas. ENIAC es generalmente reconocida como la primera computadora digital totalmente electr√≥nica y de prop√≥sito general del mundo.

Coloso tambi√©n podr√≠a haber calificado para este t√≠tulo, pero fue dise√±ado exclusivamente para un trabajo (descifrado de c√≥digo); Como no pod√≠a almacenar un programa, no pod√≠a reprogramarse f√°cilmente para hacer otras cosas.

ENIAC fue solo el comienzo. Sus dos inventores formaron la Eckert Mauchly Computer Corporation a fines de la d√©cada de 1940. Trabajando con un brillante matem√°tico h√∫ngaro, John von Neumann (1903‚Äì1957), con sede en la Universidad de Princeton, dise√±aron una m√°quina mejor llamada EDVAC (Electronic Discrete Variable Automatic Computer). En un trabajo clave, von Neumann ayud√≥ a definir c√≥mo la m√°quina almacenaba y procesaba sus programas, sentando las bases de c√≥mo funcionan todas las computadoras modernas. [6] Despu√©s de EDVAC, Eckert y Mauchly desarrollaron UNIVAC 1 (Computadora autom√°tica UNIVersal) en 1951.

Fueron ayudados en esta tarea por una joven matem√°tica y reserva naval estadounidense en gran parte desconocida llamada Grace Murray Hopper (1906-1992), quien originalmente empleado por Howard Aiken en el Harvard Mark I. Al igual que el tabulador de Herman Hollerith m√°s de 50 a√±os antes, UNIVAC 1 se utiliz√≥ para procesar datos del censo de EE. UU. Luego se fabric√≥ para otros usuarios y se convirti√≥ en la primera computadora comercial a gran escala del mundo.

M√°quinas como Colossus, ENIAC y Harvard Mark I compiten por el significado y el reconocimiento en la mente de los historiadores de la inform√°tica. ¬øCu√°l fue realmente la primera gran computadora moderna? Todos y ninguno: estas, y varias otras m√°quinas importantes, evolucionaron nuestra idea de la computadora electr√≥nica moderna durante el per√≠odo clave entre finales de la d√©cada de 1930 y principios de la d√©cada de 1950.

Entre esas otras m√°quinas hab√≠a computadoras pioneras creadas por acad√©micos ingleses, en particular la Manchester / Ferranti Mark I, construida en la Universidad de Manchester por Frederic Williams (1911‚Äì1977) y Thomas Kilburn (1921‚Äì2001), y la EDSAC (Electronic Delay Storage Automatic Calculadora), construida por Maurice Wilkes (1913‚Äì2010) en la Universidad de Cambridge.

## 6. **La revoluci√≥n micro electr√≥nica**

Los tubos de vac√≠o fueron un avance considerable en los interruptores de rel√©, pero las m√°quinas como la ENIAC eran notoriamente poco confiables. El t√©rmino moderno para un problema que detiene un programa de computadora es un "error".

La leyenda popular dice que esta palabra entr√≥ en el vocabulario de los programadores de computadoras en alg√∫n momento de la d√©cada de 1950 cuando las polillas, atra√≠das por las luces brillantes de los tubos de vac√≠o, volaron dentro de m√°quinas como el ENIAC, causaron un corto circuito y detuvieron el trabajo. Pero tambi√©n hubo otros problemas con los tubos de vac√≠o. Consumieron enormes cantidades de energ√≠a: el ENIAC usaba aproximadamente 2000 veces m√°s electricidad que una computadora port√°til moderna. Y ocuparon grandes cantidades de espacio.

Las necesidades militares estaban impulsando el desarrollo de m√°quinas como la ENIAC, pero el gran tama√±o de los tubos de vac√≠o ahora se hab√≠a convertido en un problema real. ABC hab√≠a usado 300 tubos de vac√≠o, Coloso ten√≠a 2000, y el ENIAC ten√≠a 18,000. Los dise√±adores de ENIAC se hab√≠an jactado de que su velocidad de c√°lculo era "al menos 500 veces mayor que la de cualquier otra m√°quina inform√°tica existente".

Pero el desarrollo de computadoras que eran de un orden de magnitud m√°s potente a√∫n habr√≠a necesitado cientos de miles o incluso millones de tubos de vac√≠o, lo que habr√≠a sido demasiado costoso, dif√≠cil de manejar y poco confiable. Por lo tanto, se requer√≠a urgentemente una nueva tecnolog√≠a.

La soluci√≥n apareci√≥ en 1947 gracias a tres f√≠sicos que trabajan en los Laboratorios Bell Telephone (Bell Labs). John Bardeen (1908‚Äì1991), Walter Brattain (1902‚Äì1987) y William Shockley (1910‚Äì1989) estaban ayudando a Bell a desarrollar una nueva tecnolog√≠a para el sistema telef√≥nico p√∫blico estadounidense, por lo que las se√±ales el√©ctricas que transmit√≠an las llamadas telef√≥nicas pod√≠an amplificarse m√°s f√°cilmente y llevado m√°s lejos.

Shockley, quien lideraba el equipo, cre√≠a que pod√≠a usar semiconductores (materiales como germanio y silicio que permiten que la electricidad fluya a trav√©s de ellos solo cuando han sido tratados de manera especial) para hacer una mejor forma de amplificadorque el tubo de vac√≠o Cuando sus primeros experimentos fallaron, hizo que Bardeen y Brattain trabajaran en la tarea por √©l.

Finalmente, en diciembre de 1947, crearon una nueva forma de amplificador que se conoci√≥ como el transistor de contacto de punto. Bell Labs acredit√≥ a Bardeen y Brattain con el transistor y les otorg√≥ una patente. Esto enfureci√≥ a Shockley y lo impuls√≥ a inventar un dise√±o a√∫n mejor, el transistor de uni√≥n, que ha formado la base de la mayor√≠a de los transistores desde entonces.

Al igual que los tubos de vac√≠o, los transistores podr√≠an usarse como amplificadores o interruptores. Pero ten√≠an varias ventajas importantes. Eran una fracci√≥n del tama√±o de los tubos de vac√≠o (generalmente del tama√±o de un guisante), no usaban energ√≠a a menos que estuvieran en funcionamiento y eran pr√°cticamente 100 por ciento confiables.

El transistor fue uno de los avances m√°s importantes en la historia de la inform√°tica y le vali√≥ a sus inventores el mayor premio de ciencias del mundo, el Premio Nobel de F√≠sica de 1956 . Para entonces, sin embargo, los tres hombres ya se hab√≠an separado. John Bardeen hab√≠a comenzado la investigaci√≥n pionera en superconductividad , lo que le har√≠a ganar un segundo Premio Nobel en 1972. Walter Brattain se mud√≥ a otra parte de los Laboratorios Bell.

William Shockley decidi√≥ quedarse con el transistor, eventualmente formando su propia corporaci√≥n para desarrollarlo a√∫n m√°s. Su decisi√≥n tendr√≠a consecuencias extraordinarias para la industria inform√°tica. Con una peque√±a cantidad de capital, Shockley se propuso contratar los mejores cerebros que pudo encontrar en las universidades estadounidenses, incluido el joven ingeniero el√©ctrico Robert Noyce (1927‚Äì1990) y el qu√≠mico de investigaci√≥n Gordon Moore(1929‚Äì). No pas√≥ mucho tiempo antes de que el estilo de gesti√≥n idiosincr√°sico y de intimidaci√≥n de Shockley molestara a sus trabajadores.

En 1956, ocho de ellos, incluidos Noyce y Moore, dejaron el transistor Shockley para fundar una compa√±√≠a propia, Fairchild Semiconductor, justo en el camino. As√≠ comenz√≥ el crecimiento de "Silicon Valley", la parte de California centrada en Palo Alto, donde desde entonces se han basado muchas de las principales empresas de inform√°tica y electr√≥nica del mundo. [8]

Fue en el edificio de Fairchild en California donde ocurri√≥ el siguiente avance, aunque, curiosamente, tambi√©n ocurri√≥ exactamente al mismo tiempo en los laboratorios de Dallas Instruments de Texas Instruments. En Dallas, un joven ingeniero de Kansas llamado Jack Kilby (1923‚Äì2005) estaba considerando c√≥mo mejorar el transistor.

Aunque los transistores fueron un gran avance en los tubos de vac√≠o, quedaba un problema clave. Las m√°quinas que usaban miles de transistores a√∫n ten√≠an que conectarse manualmente para conectar todos estos componentes. Ese proceso fue laborioso, costoso y propenso a errores.

¬øNo ser√≠a mejor, reflexion√≥ Kilby, si se pudieran hacer muchos transistores en un solo paquete?

Esto lo llev√≥ a inventar el circuito integrado "monol√≠tico" (IC), una colecci√≥n de transistores y otros componentes que podr√≠an fabricarse de una vez, en un bloque, en la superficie de un semiconductor. El invento de Kilby fue otro paso adelante, pero tambi√©n ten√≠a un inconveniente: los componentes de su circuito integrado todav√≠a ten√≠an que conectarse a mano.

Mientras Kilby estaba haciendo su gran avance en Dallas, desconocido para √©l, Robert Noyce estaba perfeccionando casi exactamente la misma idea en Fairchild en California. Sin embargo, Noyce fue mejor: encontr√≥ una manera de incluir las conexiones entre componentes en un circuito integrado, automatizando as√≠ todo el proceso.

Los circuitos integrados, tanto como los transistores, ayudaron a reducir las computadoras durante la d√©cada de 1960. En 1943, el jefe de IBM, Thomas Watson, hab√≠a bromeado: "Creo que hay un mercado mundial para unas cinco computadoras".

Solo dos d√©cadas despu√©s, la compa√±√≠a y sus competidores hab√≠an instalado alrededor de 25,000 grandes sistemas inform√°ticos en todo Estados Unidos. A medida que avanzaba la d√©cada de 1960, los circuitos integrados se volvieron cada vez m√°s sofisticados y compactos. Pronto, los ingenieros hablaron de la integraci√≥n a gran escala (LSI), en la que cientos de componentes podr√≠an agruparse en un solo chip, y luego integrarse a muy gran escala (VLSI), cuando el mismo chip podr√≠a contener miles de componentes.

La conclusi√≥n l√≥gica de toda esta miniaturizaci√≥n fue que, alg√∫n d√≠a, alguien podr√≠a exprimir una computadora completa en un chip. En 1968, Robert Noyce y Gordon Moore hab√≠an dejado Fairchild para establecer una nueva compa√±√≠a propia.

Con mucha integraci√≥n en sus mentes, lo llamaron Integrated Electronics o Intel para abreviar. Originalmente hab√≠an planeado hacer chips de memoria, pero cuando la compa√±√≠a obtuvo una orden para hacer chips para una gama de calculadoras de bolsillo, la historia se dirigi√≥ en una direcci√≥n diferente. Un par de sus ingenieros, Federico Faggin (1941‚Äì) y Marcian Edward (Ted) Hoff(1937‚Äì), se dieron cuenta de que en lugar de hacer una gama de chips especializados para una gama de calculadoras, podr√≠an hacer un chip universal que pudiera programarse para funcionar en todos ellos.

As√≠ naci√≥ la computadora de un solo chip de uso general o el microprocesador, y eso provoc√≥ la siguiente fase de la revoluci√≥n de la computadora.

## 7. **Computadoras personales**

Los circuitos integrados, tanto como los transistores, ayudaron a reducir las computadoras durante la d√©cada de 1960. En 1943, el jefe de IBM, Thomas Watson, hab√≠a bromeado: "Creo que hay un mercado mundial para unas cinco computadoras".

Solo dos d√©cadas despu√©s, la compa√±√≠a y sus competidores hab√≠an instalado alrededor de 25,000 grandes sistemas inform√°ticos en todo Estados Unidos. A medida que avanzaba la d√©cada de 1960, los circuitos integrados se volvieron cada vez m√°s sofisticados y compactos. Pronto, los ingenieros hablaron de la integraci√≥n a gran escala (LSI), en la que cientos de componentes podr√≠an agruparse en un solo chip, y luego integrarse a muy gran escala (VLSI), cuando el mismo chip podr√≠a contener miles de componentes.

La conclusi√≥n l√≥gica de toda esta miniaturizaci√≥n fue que, alg√∫n d√≠a, alguien podr√≠a exprimir una computadora completa en un chip. En 1968, Robert Noyce y Gordon Moore hab√≠an dejado Fairchild para establecer una nueva compa√±√≠a propia.

Con mucha integraci√≥n en sus mentes, lo llamaron Integrated Electronics o Intel para abreviar. Originalmente hab√≠an planeado hacer chips de memoria, pero cuando la compa√±√≠a obtuvo una orden para hacer chips para una gama de calculadoras de bolsillo, la historia se dirigi√≥ en una direcci√≥n diferente.

Un par de sus ingenieros, Federico Faggin (1941‚Äì) y Marcian Edward (Ted) Hoff(1937‚Äì), se dieron cuenta de que en lugar de hacer una gama de chips especializados para una gama de calculadoras, podr√≠an hacer un chip universal que pudiera programarse para funcionar en todos ellos. As√≠ naci√≥ la computadora de un solo chip de uso general o el microprocesador, y eso provoc√≥ la siguiente fase de la revoluci√≥n de la computadora.

El √©xito de la venta de Apple a las empresas fue un gran shock para IBM y las otras grandes empresas que dominaron la industria inform√°tica. No se necesit√≥ una hoja de c√°lculo de VisiCalc para darse cuenta de que, si la tendencia continuaba, empresas nuevas como Apple socavar√≠an el inmensamente lucrativo mercado comercial de computadoras "Big Blue" de IBM. En 1980, IBM finalmente se dio cuenta de que ten√≠a que hacer algo y lanz√≥ un proyecto altamente racionalizado para salvar su negocio. Un a√±o despu√©s, lanz√≥ la IBM Personal Computer (PC), basada en un microprocesador Intel 8080, que revirti√≥ r√°pidamente la fortuna de la compa√±√≠a y rob√≥ el mercado a Apple.

La PC tuvo √©xito esencialmente por una raz√≥n. Todas las docenas de microcomputadoras que se lanzaron en la d√©cada de 1970, incluida Apple] [- eran incompatibles. Todos usaron hardware diferente y trabajaron de diferentes maneras. La mayor√≠a se programaron usando un lenguaje simple, similar al ingl√©s llamado BASIC, pero cada uno us√≥ su propio sabor de BASIC, que estaba estrechamente relacionado con el dise√±o del hardware de la m√°quina.

Como resultado, los programas escritos para una m√°quina generalmente no se ejecutar√≠an en otra sin una gran conversi√≥n. Las empresas que escribieron software profesionalmente lo escribieron solo para una m√°quina y, en consecuencia, no hab√≠a industria del software para hablar.

En 1976, Gary Kildall(1942‚Äì1994), profesor e inform√°tico, y uno de los fundadores del Homebrew Computer Club, hab√≠a encontrado una soluci√≥n a este problema. Kildall escribi√≥ un sistema operativo (software de control fundamental de una computadora) llamado CP / M que actu√≥ como intermediario entre los programas del usuario y el hardware de la m√°quina.

Con un golpe de genio, Kildall se dio cuenta de que todo lo que ten√≠a que hacer era reescribir CP / M para que funcionara en cada m√°quina diferente. Entonces, todas esas m√°quinas podr√≠an ejecutar programas de usuario id√©nticos, sin ninguna modificaci√≥n, dentro de CP / M. Eso har√≠a que todos los diferentes microordenadores sean compatibles de un solo golpe. A principios de la d√©cada de 1980, Kildall se hab√≠a convertido en multimillonario gracias al √©xito de su invenci√≥n: el primer sistema operativo de computadora personal. Naturalmente, cuando IBM estaba desarrollando su computadora personal, se le acerc√≥ esperando poner CP / M en su propia m√°quina.

La leyenda dice que Kildall estaba volando su avi√≥n personal cuando IBM llam√≥, por lo que se perdi√≥ una de las mejores ofertas del mundo. Pero la verdad parece haber sido que IBM quer√≠a comprar CP / M directamente por solo $ 200,000, mientras que Kildall reconoci√≥ que su producto val√≠a millones m√°s y se neg√≥ a venderlo. En cambio, IBM recurri√≥ a un joven programador llamadoBill Gates (1955‚Äì). Su entonces peque√±a empresa, Microsoft, cre√≥ r√°pidamente un sistema operativo llamado DOS, basado en un producto llamado QDOS (Sistema operativo r√°pido y sucio), que adquirieron de Seattle Computer Products.

Algunos creen que Microsoft e IBM enga√±aron a Kildall de su lugar en la historia de la computadora; El propio Kildall los acus√≥ de copiar sus ideas. Otros piensan que Gates era simplemente el hombre de negocios m√°s astuto. De cualquier manera, la PC IBM, impulsada por el sistema operativo de Microsoft, fue un gran √©xito.

Sin embargo, la victoria de IBM fue de corta duraci√≥n. Curiosamente, Bill Gates hab√≠a vendido a IBM los derechos de una versi√≥n de DOS (PC-DOS) y retuvo los derechos de una versi√≥n muy similar (MS-DOS) para su propio uso.

Cuando otros fabricantes de computadoras, especialmente Compaq y Dell, comenzaron a fabricar hardware compatible con IBM (o "clonado"), tambi√©n acudieron a Gates para obtener el software. IBM cobraba una prima por las m√°quinas que llevaban su insignia, pero los consumidores pronto se dieron cuenta de que las PC eran productos b√°sicos: conten√≠an componentes casi id√©nticos, un microprocesador Intel, por ejemplo, sin importar el nombre que ten√≠an en el caso. A medida que IBM perdi√≥ cuota de mercado, los √∫ltimos vencedores fueron Microsoft e Intel, que pronto suministraron el software y el hardware para casi todas las PC del planeta. Apple, IBM.

## 8. **La revoluci√≥n del usuario**

Afortunadamente para Apple, tuvo otra gran idea. Uno de los trajes m√°s fuertes del Apple II fue su simple "facilidad de uso". Para Steve Jobs, desarrollar computadoras verdaderamente f√°ciles de usar se convirti√≥ en una misi√≥n personal a principios de la d√©cada de 1980. Lo que realmente lo inspir√≥ fue una visita al PARC (Centro de Investigaci√≥n de Palo Alto), un laboratorio inform√°tico de vanguardia que luego funcionaba como una divisi√≥n de la Corporaci√≥n Xerox. Xerox hab√≠a comenzado a desarrollar computadoras a principios de la d√©cada de 1970, creyendo que har√≠an papel (y las fotocopiadoras altamente lucrativas)Xerox hecho) obsoleto.

Uno de los proyectos de investigaci√≥n de PARC fue una computadora avanzada de $ 40,000 llamada Xerox Alto. A diferencia de la mayor√≠a de las microcomputadoras lanzadas en la d√©cada de 1970, que se programaron escribiendo comandos de texto, el Alto ten√≠a una pantalla similar al escritorio con peque√±os √≠conos de im√°genes que se pod√≠an mover con un mouse: era la primera interfaz gr√°fica de usuario (GUI, pronunciada "pegajoso") - una idea concebida por Alan Kay (1940‚Äì) y que ahora se usa en pr√°cticamente todas las computadoras modernas. El Alto tom√≥ prestadas algunas de sus ideas, incluido el mouse , del pionero inform√°tico de los a√±os sesenta Douglas Engelbart (1925‚Äì2013).

De vuelta en Apple, Jobs lanz√≥ su propia versi√≥n del proyecto Alto para desarrollar una computadora f√°cil de usar llamada PITS (Person In The Street). Esta m√°quina se convirti√≥ en Apple Lisa, lanzada en enero de 1983, la primera computadora ampliamente disponible con un escritorio GUI. Con un precio minorista de $ 10,000, m√°s del triple del costo de una PC IBM, la Lisa fue un fracaso comercial.

Pero allan√≥ el camino para una m√°quina mejor y m√°s barata llamada Macintosh que Jobs present√≥ un a√±o despu√©s, en enero de 1984. Con su memorable anuncio de lanzamiento para Macintosh inspirado en la novela 1984 de George Orwell y dirigida por Ridley Scott (director del dist√≥pico) pel√≠cula Blade Runner), Apple golpe√≥ el monopolio de IBM, criticando lo que describi√≥ como el enfoque dominante, incluso totalitario, de la empresa: Big Blue era realmente Big Brother. 

El anuncio de Apple promet√≠a una visi√≥n muy diferente: "El 24 de enero, Apple Computer presentar√° Macintosh. Y ver√° por qu√© 1984 no ser√° como '1984'". El Macintosh fue un √©xito cr√≠tico y ayud√≥ a inventar el nuevo campo de la edici√≥n de escritorio a mediados de la d√©cada de 1980, sin embargo, nunca estuvo cerca de desafiar la posici√≥n de IBM.

Ir√≥nicamente, la m√°quina f√°cil de usar de Jobs tambi√©n ayud√≥ a Microsoft a desalojar a IBM como la fuerza l√≠der mundial en inform√°tica. Cuando Bill Gates vio c√≥mo funcionaba el Macintosh, con su escritorio de icono de imagen f√°cil de usar, lanz√≥ Windows, una versi√≥n mejorada de su software MS-DOS.

Apple vio esto como un plagio flagrante y present√≥ una demanda por derechos de autor de $ 5,5 mil millones en 1988. Cuatro a√±os m√°s tarde, el caso colaps√≥ con Microsoft asegurando efectivamente el derecho a usar el "aspecto" de Macintosh en todas las versiones actuales y futuras de Windows. El sistema Windows 95 de Microsoft, lanzado tres a√±os despu√©s, ten√≠a un escritorio f√°cil de usar, similar a Macintosh y MS-DOS ejecut√°ndose detr√°s de escena.

## 9. **De las redes a internet**

Las PC estandarizadas que ejecutan software estandarizado trajeron un gran beneficio para las empresas: las computadoras pod√≠an conectarse en redes para compartir informaci√≥n. En Xerox PARC en 1973, el ingeniero el√©ctrico Bob Metcalfe (1946‚Äì) desarroll√≥ una nueva forma de vincular computadoras "a trav√©s del √©ter" (espacio vac√≠o) que llam√≥ Ethernet.

Unos a√±os m√°s tarde, Metcalfe dej√≥ Xerox para formar su propia compa√±√≠a, 3Com, para ayudar a las empresas a cumplir la "Ley de Metcalfe": las computadoras se vuelven √∫tiles cuanto m√°s conectadas est√°n con las computadoras de otras personas. A medida que m√°s y m√°s empresas exploran el poder de las redes de √°rea local (LAN), a medida que avanza la d√©cada de 1980.

Hoy, la WAN m√°s conocida es Internet , una red global de computadoras y LAN individuales que conecta a cientos de millones de personas. La historia de Internet es otra historia, pero comenz√≥ en la d√©cada de 1960 cuando cuatro universidades estadounidenses lanzaron un proyecto para conectar sus sistemas inform√°ticos para crear la primera WAN.

M√°s tarde, con fondos para el Departamento de Defensa, esa red se convirti√≥ en un proyecto m√°s grande llamado ARPANET (Red de Agencias de Proyectos de Investigaci√≥n Avanzada). A mediados de la d√©cada de 1980, la Fundaci√≥n Nacional de Ciencias de EE. UU. (NSF) lanz√≥ su propia WAN llamada NSFNET. La convergencia de todas estas redes produjo lo que ahora llamamos Internet m√°s adelante en la d√©cada de 1980.

Poco despu√©s, el poder de las redes le dio al programador inform√°tico brit√°nico Tim Berners-Lee(1955‚Äì) su gran idea: combinar el poder de las redes de computadoras con la idea de compartir informaci√≥n que Vannevar Bush hab√≠a propuesto en 1945.

As√≠ naci√≥ la World Wide Web , una manera f√°cil de compartir informaci√≥n a trav√©s de una red de computadoras, lo que hizo posible la era moderna de la computaci√≥n en la nube (donde cualquiera puede acceder a una gran potencia inform√°tica a trav√©s de Internet sin tener que preocuparse por d√≥nde o c√≥mo se procesan sus datos). ¬°Es el invento de Tim Berners-Lee el que te trae esta historia de la inform√°tica en macetas hoy!

## 10. **¬øQu√© nos espera en el futuro?**

**¬øQu√© hay del futuro?** El poder de las computadoras (la cantidad de componentes empaquetados en un chip) se ha duplicado aproximadamente cada 18 meses a 2 a√±os desde la d√©cada de 1960. Pero se espera que las leyes de la f√≠sica detengan la Ley de Moore , como se conoce esta idea, y nos obligan a explorar formas completamente nuevas de construir computadoras.

**¬øC√≥mo ser√°n las PC del ma√±ana?** Una idea muy esperada es que usar√°n part√≠culas de luz (fotones) en lugar de electrones, un enfoque conocido como computaci√≥n √≥ptica o fot√≥nica. Actualmente, gran parte del dinero inteligente est√° apostando por computadoras cu√°nticas , que implementan formas astutas de manipular √°tomos para procesar y almacenar informaci√≥n a la velocidad del rayo.

Tambi√©n hay esperanza de que podamos usar spintronics (aprovechando el "giro" de las part√≠culas) y tecnolog√≠a biomolecular (computaci√≥n con ADN, prote√≠nas y otras mol√©culas biol√≥gicas), aunque ambas se encuentran en las primeras etapas de la investigaci√≥n.

Las virutas hechas de nuevos materiales como el grafeno tambi√©n pueden ofrecer formas de extender la ley de Moore. Independientemente de la tecnolog√≠a que gane, ¬°puede estar seguro de que el futuro de la inform√°tica ser√° tan emocionante como el pasado!

üî• Seguro tambi√©n te interesa: [C√≥mo aprender Python en 2020](/python/), [ü•á ‚ñ∑ C√≥mo aprender aprendizaje autom√°tico o machine learning en 2020 ü§ñ](/que-aprender-sobre-machine-learning-2020/), [‚ñ∑ M√°s de 200 de los mejores tutoriales de aprendizaje autom√°tico, PNL y Python](/aprendizaje-automatico-cursos-ingles/)
{: .notice--danger}

### Relacionados



<div class="fb-post" data-href="https://www.facebook.com/ciberninjas/posts/1331109157075936" data-width="850" data-show-text="true"><blockquote cite="https://developers.facebook.com/ciberninjas/posts/1331109157075936" class="fb-xfbml-parse-ignore"><p>üë®‚Äçüíª Los mejores libros con los que aprender a programar en Java y con Android, en Espa√±ol</p>Publicada por <a href="https://www.facebook.com/ciberninjas/">Ciberninjas</a> en&nbsp;<a href="https://developers.facebook.com/ciberninjas/posts/1331109157075936">Martes, 3 de marzo de 2020</a></blockquote></div>
